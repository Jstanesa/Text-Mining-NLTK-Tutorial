{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the tutorial will cover sentiment extraction. We will examine documents and assign them a score from positive to negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firt, we'll grab some documents that have been categorized as either negative (neg) or positive (pos) from NLTK's movie review corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write a function that will build a featureset for each one of these documents. Our featureset is a bag of words that contains all of the words appearing in our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    words = [w.lower() for w in words]\n",
    "    myDict = dict([(word, True) for word in words])\n",
    "    return myDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract our features, and divide our data, so that we have a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    " \n",
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4\n",
    "\n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train our classifier, test it's accuracy, and then print out the most informative features in our featureset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we can classify a new review by feeding it to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "0.999997377199\n",
      "2.62280111245e-06\n"
     ]
    }
   ],
   "source": [
    "temp = classifier.prob_classify(testfeats[7][0])\n",
    "print temp.samples()\n",
    "print temp.prob('neg')\n",
    "print temp.prob('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's look at another aplication of Naive Bayes Classification, from the NLTK book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to classify names by gender, based on a featureset we design. First, let's import some labeled names, and then shuffle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose what features these names are going to have. Each name is like a document. Where we had given each movie review a feature for every word it had, in this case we are going to give every name a feature corresponding to the last letter in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "     return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct our training and test sets in the same way we did for our sentiment analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureset = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "trainfeats2, testfeats2 = featureset[500:], featureset[:500]\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(trainfeats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.79\n",
      "Most Informative Features\n",
      "             last_letter = u'a'           female : male   =     33.4 : 1.0\n",
      "             last_letter = u'k'             male : female =     29.1 : 1.0\n",
      "             last_letter = u'f'             male : female =     27.5 : 1.0\n",
      "             last_letter = u'p'             male : female =     20.8 : 1.0\n",
      "             last_letter = u'v'             male : female =     11.1 : 1.0\n",
      "              sec_letter = u'z'             male : female =     10.7 : 1.0\n",
      "             last_letter = u'd'             male : female =     10.0 : 1.0\n",
      "             last_letter = u'o'             male : female =      9.0 : 1.0\n",
      "             last_letter = u'm'             male : female =      8.8 : 1.0\n",
      "   second_to_last_letter = u'o'             male : female =      7.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy:', nltk.classify.util.accuracy(classifier2, testfeats2)\n",
    "classifier2.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = classifier2.prob_classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male', 'female']\n",
      "0.83038276398\n"
     ]
    }
   ],
   "source": [
    "print temp.samples()\n",
    "print temp.prob('male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can modify our featureset to include anything we think might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    myDict = dict()\n",
    "    myDict['first_letter'] = word[0]\n",
    "    myDict['last_letter'] = word[-1]\n",
    "    return myDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
